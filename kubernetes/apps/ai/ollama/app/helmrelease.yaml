---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app ollama-ipex
  namespace: ai
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 3.6.1
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  maxHistory: 1
  install:
    remediation:
      retries: 1
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 1
  uninstall:
    keepHistory: false
  dependsOn:
    - name: intel-device-plugin-gpu
      namespace: kube-system
  values:
    controllers:
      main:
        type: statefulset
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          main:
            image:
              repository: ubuntu
              tag: 24.04
            env:
              OLLAMA_HOST: "0.0.0.0:11434"
              DEBIAN_FRONTEND: "noninteractive"
              TZ: "america/los_angeles"
            command:
              - "/bin/bash"
              - "-c"
              - |
                if [ -f "/INSTALLED" ]; then
                  echo "Installation already completed. Starting Ollama..."
                  export OLLAMA_HOST=0.0.0.0:11434
                  exec /start-ollama.sh
                else
                  apt update
                  apt install --no-install-recommends -q -y software-properties-common ca-certificates wget ocl-icd-libopencl1 zsh vim curl git
                  mkdir -p /tmp/gpu
                  cd /tmp/gpu
                  wget https://github.com/oneapi-src/level-zero/releases/download/v1.19.2/level-zero_1.19.2+u24.04_amd64.deb
                  wget https://github.com/intel/intel-graphics-compiler/releases/download/v2.5.6/intel-igc-core-2_2.5.6+18417_amd64.deb
                  wget https://github.com/intel/intel-graphics-compiler/releases/download/v2.5.6/intel-igc-opencl-2_2.5.6+18417_amd64.deb
                  wget https://github.com/intel/compute-runtime/releases/download/24.52.32224.5/intel-level-zero-gpu_1.6.32224.5_amd64.deb
                  wget https://github.com/intel/compute-runtime/releases/download/24.52.32224.5/intel-opencl-icd_24.52.32224.5_amd64.deb
                  wget https://github.com/intel/compute-runtime/releases/download/24.52.32224.5/libigdgmm12_22.5.5_amd64.deb
                  dpkg -i *.deb
                  rm *.deb
                  cd /
                  wget https://github.com/mattcurf/ollama-intel-gpu/releases/download/v0.0.1/ollama-0.5.4-ipex-llm-2.2.0b20250220-ubuntu.tgz
                  mkdir -p /usr/local
                  tar xvf ollama-0.5.4-ipex-llm-2.2.0b20250220-ubuntu.tgz -C /usr/local
                  rm ollama-0.5.4-ipex-llm-2.2.0b20250220-ubuntu.tgz
                  ln -sf /usr/local/ollama-0.5.4-ipex-llm-2.2.0b20250220-ubuntu/ollama /usr/local/bin/ollama
                  echo -e "#!/bin/bash\nexport OLLAMA_HOST=0.0.0.0:11434\n/usr/local/bin/ollama serve" > /start-ollama.sh
                  chmod +x /start-ollama.sh
                  touch /INSTALLED
                  echo "Intel GPU setup complete. Starting Ollama..."
                  export OLLAMA_HOST=0.0.0.0:11434
                  exec /start-ollama.sh
                fi
            securityContext:
              privileged: true
              capabilities:
                add:
                  - SYS_ADMIN
              allowPrivilegeEscalation: true
              runAsUser: 0
            resources:
              requests:
                cpu: 500m
                memory: 16Gi
                gpu.intel.com/i915: 1
              limits:
                gpu.intel.com/i915: 1
    service:
      main:
        ports:
          http:
            port: 11434
    persistence:
      config:
        enabled: true
        existingClaim: ollama-ipex-config
        globalMounts:
          - path: /

    hostNetwork: false
    securityContext:
      privileged: true
      capabilities:
        add:
          - SYS_ADMIN
      allowPrivilegeEscalation: true
      runAsUser: 0
      runAsGroup: 0
      fsGroup: 0
    podSecurityContext:
      hostPID: true
      hostIPC: true

