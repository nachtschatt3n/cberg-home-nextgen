---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: influxdb
  namespace: databases
spec:
  interval: 25m
  chart:
    spec:
      # renovate: registryUrl=https://helm.influxdata.com/
      chart: influxdb2
      version: 2.1.2
      sourceRef:
        kind: HelmRepository
        name: influxdata
        namespace: flux-system
      interval: 15m
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  values:
    ## influxdb image version
    ## ref: https://hub.docker.com/r/library/influxdb/tags/
    image:
      repository: docker.io/library/influxdb
      tag: "2.7.4-alpine"
      pullPolicy: IfNotPresent

    serviceAccount:
      create: true

    ## Customize liveness, readiness and startup probes
    ## ref: https://docs.influxdata.com/influxdb/v1.8/tools/api/#ping-http-endpoint
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
    ##
    livenessProbe: {}
    # path: "/ping"
    # initialDelaySeconds: 30
    # timeoutSeconds: 5
    # scheme: HTTP

    readinessProbe: {}
    # path: "/ping"
    # initialDelaySeconds: 5
    # timeoutSeconds: 1
    # scheme: HTTP

    securityContext: {}
    # runAsUser: 999
    # runAsGroup: 999

    startupProbe:
      enabled: false
      # path: "/ping"
      # failureThreshold: 6
      # periodSeconds: 5
      # scheme: HTTP

    ## Specify a service type and optional port
    ## NodePort is default
    ## ref: http://kubernetes.io/docs/user-guide/services/
    ##
    service:
      type: ClusterIP
      externalTrafficPolicy: Cluster
      ports:
        http:
          port: 8086
        rpc:
          enabled: true
          port: 8088

    ingress:
      enabled: true
      className: internal
      annotations:
        gethomepage.dev/enabled: "true"
        gethomepage.dev/name: "Influx DB"
        gethomepage.dev/description: "InfluxDB is an open-source time series database"
        gethomepage.dev/group: "Databases"
        gethomepage.dev/icon: "influxdb.png"
      labels:
        gethomepage.dev/enabled: "true"
      hostname: &host "influx.${SECRET_DOMAIN}"
      hosts:
        - &host "influx.${SECRET_DOMAIN}"
      tls:
        - hosts:
            - *host

    ## Persist data to a persistent volume
    ##
    persistence:
      enabled: true
      useExisting: true
      name: influxdb2-data

    setDefaultUser:
      enabled: true
      user:
        ## The user name
        ## Default: "admin"
        #username: "admin"

        ## User password
        ## single quotes must be escaped (\')
        ## Default: (Randomly generated 10 characters of AlphaNum)
        # password:

        ## The user name and password are obtained from an existing secret. The expected
        ## keys are `influxdb-user` and `influxdb-password`.
        ## If set, the username and password values above are ignored.
        existingSecret: influxdb-auth

    ## Configure resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    resources:
      requests:
        memory: 256Mi
        cpu: 0.1
      limits:
        memory: 2Gi
        cpu: 2

    # Annotations to be added to InfluxDB pods
    podAnnotations: {}

    # Labels to be added to InfluxDB pods
    podLabels: {}

    ## Add custom volume and volumeMounts
    # volumes:
    #   - name: ssl-cert-volume
    #     secret:
    #       secretName: secret-name
    # mountPoints:
    #   - name: ssl-cert-volume
    #     mountPath: /etc/ssl/certs/selfsigned/
    #     readOnly: true

    ## Additional containers to be added to the pod.
    extraContainers: {}
    #  - name: my-sidecar
    #    image: nginx:latest

    ## Use an alternate scheduler, e.g. "stork".
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
    ##
    # schedulerName:

    ## Node labels for pod assignment
    ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}

    ## Affinity for pod assignment
    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ##
    affinity: {}

    ## Tolerations for pod assignment
    ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    # - key: "key"
    #   operator: "Equal|Exists"
    #   value: "value"
    #   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

    ## The InfluxDB image uses several environment variables to automatically
    ## configure certain parts of the server.
    ## Ref: https://hub.docker.com/_/influxdb/
    env: {}
    # - name: INFLUXDB_DB
    #   value: "demo"

    ## The name of a secret in the same kubernetes namespace which contain values
    ## to be added to the environment.
    ## This can be used, for example, to set the INFLUXDB_HTTP_SHARED_SECRET
    ## environment variable.
    envFromSecret: {}

    ## InfluxDB configuration
    ## ref: https://docs.influxdata.com/influxdb/v1.8/administration/config
    config:
      reporting_disabled: false
      rpc:
        bind-address: ":8088"
      meta: {}
      data: {}
      coordinator: {}
      retention: {}
      shard_precreation: {}
      monitor: {}
      http:
        enabled: true
        bind-address: ":8086"
        flux-enabled: true
      logging: {}
      subscriber: {}
      graphite: {}
      collectd: {}
      opentsdb: {}
      udp: {}
      continuous_queries: {}
      tls: {}

    # Allow executing custom init scripts
    #
    # If the container finds any files with the extensions .sh or .iql inside of the
    # /docker-entrypoint-initdb.d folder, it will execute them. The order they are
    # executed in is determined by the shell. This is usually alphabetical order.
    initScripts:
      enabled: false
      scripts:
        init.iql: |+
          CREATE DATABASE "telegraf" WITH DURATION 30d REPLICATION 1 NAME "rp_30d"

    backup:
      enabled: false
      ## By default emptyDir is used as a transitory volume before uploading to object store.
      ## As such, ensure that a sufficient ephemeral storage request is set to prevent node disk filling completely.
      resources:
        requests:
          # memory: 512Mi
          # cpu: 2
          #ephemeral-storage: "8Gi"
        # limits:
          # memory: 1Gi
          # cpu: 4
          # ephemeral-storage: "16Gi"
      ## If backup destination is PVC, or want to use intermediate PVC before uploading to object store.
      persistence:
        enabled: false
        ## If defined, storageClassName: <storageClass>
        ## If set to "-", storageClassName: "", which disables dynamic provisioning
        ## If undefined (the default) or set to null, no storageClassName spec is
        ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
        ##   GKE, AWS & OpenStack)
        ##
        # storageClass: "-"
        annotations:
        accessMode: ReadWriteOnce
        size: 8Gi
      schedule: "0 0 * * *"
      startingDeadlineSeconds: ""
      annotations: {}
      podAnnotations: {}
      nodeSelector: {}

      ## Google Cloud Storage
      # gcs:
        # serviceAccountSecret: influxdb-backup-key
        # serviceAccountSecretKey: key.json
        # destination: gs://bucket/influxdb

      ## Azure
      ## Secret is expected to have connection string stored in `connection-string` field
      ## Existing container will be used or private one withing storage account will be created.
      # azure:
        # storageAccountSecret: influxdb-backup-azure-key
        # destination_container: influxdb-container
        # destination_path: ""

      ## Amazon S3 or compatible
      ## Secret is expected to have AWS (or compatible) credentials stored in `credentials` field.
      ## Please look at https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html#cli-configure-files-where
      ## for the credentials format.
      ## The bucket should already exist.
      # s3:
        # credentialsSecret: aws-credentials-secret
        # destination: s3://bucket/path
        ## Optional. Specify if you're using an alternate S3 endpoint.
        # endpointUrl: ""

    backupRetention:
      enabled: false
      resources:
        requests:
          # memory: 512Mi
          # cpu: 2
        # limits:
          # memory: 1Gi
          # cpu: 4
      schedule: "0 0 * * *"
      startingDeadlineSeconds:
      annotations: {}
      podAnnotations: {}
      daysToRetain: 7
      # s3:
      #   credentialsSecret: aws-credentials-secret
      #   bucketName: bucket
      #   ## Optional. Specify if you're using an alternate S3 endpoint.
      #   # endpointUrl: ""
