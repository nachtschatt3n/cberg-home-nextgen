# Security Audit Runbook

## Purpose

This runbook provides a systematic, AI-executable security audit for the home lab Kubernetes cluster and network. Execute checks in section order, collecting results and producing `runbooks/security-check-current.md`.

## Severity Model

- ðŸ”´ **Critical** â€” act immediately (exposed secret, active attack indicator, unexpected public exposure)
- ðŸŸ¡ **Warning** â€” remediate within a week (misconfiguration, policy gap, elevated risk)
- ðŸŸ¢ **OK** â€” compliant, no action needed

## Output

Results are written to `runbooks/security-check-current.md` with all sensitive values replaced:
- Actual domain â†’ `[DOMAIN]`
- Git user name â†’ `[NAME]`
- Git user email â†’ `[EMAIL]`

---

## Preparation (Run First)

### Load Sensitive Variables

```bash
# Load sensitive patterns from SOPS â€” never hardcode these in this file or the output
DOMAIN=$(sops -d kubernetes/flux/components/common/cluster-secrets.sops.yaml \
  | grep 'SECRET_DOMAIN:' | awk '{print $2}' | tr -d '"')
GIT_NAME=$(git config user.name)
GIT_EMAIL=$(git config user.email)

# Verify they loaded (check lengths, not values)
echo "DOMAIN loaded: ${#DOMAIN} chars"
echo "GIT_NAME loaded: ${#GIT_NAME} chars"
echo "GIT_EMAIL loaded: ${#GIT_EMAIL} chars"
```

### Verify Tool Availability

```bash
which kubectl sops git python3 curl openssl unifictl
kubectl cluster-info
```

### Start Output File

```bash
cat > runbooks/security-check-current.md << EOF
# Security Audit â€” $(date '+%Y-%m-%d %H:%M %Z')

> Auto-generated by security-check.md â€” do not hand-edit. Sensitive values redacted.

EOF
```

---

## 1. SOPS Encryption Coverage

**Objective**: Confirm every Kubernetes Secret manifest is SOPS-encrypted; find temp decrypted files on disk.

**Commands:**

```bash
# Find kind: Secret YAML files NOT ending in .sops.yaml (should return nothing)
echo "=== Unencrypted Secret manifests ==="
grep -rl 'kind: Secret' kubernetes/ --include="*.yaml" | grep -v '\.sops\.yaml$'

# Find .decrypted~ temp files left by the SOPS editor
echo "=== SOPS editor temp files ==="
find kubernetes/ talos/ -name '.decrypted~*' -type f 2>/dev/null

# Find suspiciously long base64 strings (>40 chars) outside .sops.yaml files
# Excludes SOPS metadata lines and comments
echo "=== Suspicious base64 outside sops files ==="
grep -rE '[A-Za-z0-9+/]{40,}={0,2}' kubernetes/ --include="*.yaml" \
  | grep -v '\.sops\.yaml' \
  | grep -v 'sops:' \
  | grep -v '#' \
  | head -20
```

**Expected results:**
- Zero unencrypted Secret files
- Zero `.decrypted~` temp files
- Zero suspicious base64 outside `.sops.yaml` (chart SHA digests are acceptable â€” verify context)

**Severity:**
- ðŸ”´ Critical if any unencrypted `kind: Secret` file found
- ðŸ”´ Critical if `.decrypted~` temp files exist (may contain live secrets on disk)
- ðŸŸ¡ Warning if base64 strings found â€” investigate each to confirm they are not secret values

---

## 2. Sensitive Data Exposure Scan

**Objective**: Confirm `$DOMAIN`, `$GIT_NAME`, `$GIT_EMAIL` do not appear in plaintext in tracked files.

**Commands (all use runtime variables, never literals):**

```bash
echo "=== Domain exposure in tracked non-sops files ==="
git ls-files | grep -v '\.sops\.yaml$' | xargs grep -l "$DOMAIN" 2>/dev/null \
  | sed "s/$DOMAIN/[DOMAIN]/g"

echo "=== Name exposure in tracked non-sops files ==="
git ls-files | grep -v '\.sops\.yaml$' | xargs grep -il "$GIT_NAME" 2>/dev/null

echo "=== Email exposure in tracked non-sops files ==="
git ls-files | grep -v '\.sops\.yaml$' | xargs grep -l "$GIT_EMAIL" 2>/dev/null

echo "=== Domain in public-facing docs ==="
grep -ril "$DOMAIN" README.md docs/ runbooks/ 2>/dev/null \
  | sed "s/$DOMAIN/[DOMAIN]/g"
```

**Expected results:**
- Domain appears only as `${SECRET_DOMAIN}` placeholder (Flux substitution syntax) â€” never the literal value
- No name or email in tracked files

**Severity:**
- ðŸ”´ Critical if literal domain or personal info found in any tracked file
- ðŸŸ¢ OK if only `${SECRET_DOMAIN}` placeholders found

---

## 3. Git History Secret Scan

**Objective**: Detect secrets that were committed and later deleted; catch accidental history leaks.

**Commands:**

```bash
echo "=== Plaintext credential patterns in git history ==="
git log --all --oneline -p \
  | grep -iE '(password|secret|token|api.?key|private.?key)\s*[:=]\s*\S{8,}' \
  | grep -v 'sops\|ENC\[AES\|secretKeyRef\|valueFrom\|EXAMPLE\|your_\|placeholder\|changeme' \
  | head -30

echo "=== Domain literal in git history (non-sops files) ==="
git log --all -p -S "$DOMAIN" -- $(git ls-files | grep -v '\.sops\.yaml$') 2>/dev/null \
  | head -50 \
  | sed "s/$DOMAIN/[DOMAIN]/g"

echo "=== Secret/password filenames ever committed outside .sops.yaml ==="
git log --all --diff-filter=A --name-only --pretty=format: \
  | grep -i 'secret\|password\|credential\|private.key' \
  | grep -v '\.sops\.yaml$' \
  | sort -u
```

**Expected results:**
- No plaintext credential patterns in history (`.sops.yaml` additions are expected and safe)
- No literal domain in non-sops file history
- No plaintext secret filenames ever added

**Severity:**
- ðŸ”´ Critical if plaintext credentials found in history (requires git history rewrite + secret rotation)
- ðŸŸ¡ Warning if domain literal appears in deleted content â€” assess exposure window

---

## 4. CVE / Vulnerability Check

**Objective**: Cross-reference current component versions against OSV.dev for known CVEs.

**Commands:**

```bash
# Check Renovate PRs labeled 'security'
echo "=== Open Renovate security PRs ==="
gh pr list --label security --state open

# Check OSV.dev for top components
echo "=== OSV.dev CVE check (top components) ==="
python3 << 'PYEOF'
import re, json, urllib.request, time

try:
    with open("runbooks/version-check-current.md") as f:
        content = f.read()
except FileNotFoundError:
    print("version-check-current.md not found â€” run version-check runbook first")
    exit(0)

# Extract name | current-version pairs from the Quick Overview table
rows = re.findall(r'\|\s*`([^`]+)`\s*\|\s*`([^`]+)`\s*\|', content)

def check_osv(package, version):
    clean_ver = version.lstrip('v').split('-')[0]  # strip v-prefix and OS suffixes
    payload = json.dumps({
        "version": clean_ver,
        "package": {"name": package, "ecosystem": "Helm"}
    }).encode()
    req = urllib.request.Request(
        "https://api.osv.dev/v1/query",
        data=payload,
        headers={"Content-Type": "application/json"}
    )
    try:
        with urllib.request.urlopen(req, timeout=5) as r:
            data = json.load(r)
            return data.get("vulns", [])
    except Exception as e:
        return []

found_vulns = False
for name, ver in rows[:25]:  # limit to avoid rate limiting
    time.sleep(0.2)
    vulns = check_osv(name, ver)
    if vulns:
        ids = [v['id'] for v in vulns]
        print(f"ðŸ”´ {name} {ver}: {len(vulns)} CVE(s) â€” {ids}")
        found_vulns = True

if not found_vulns:
    print("ðŸŸ¢ No CVEs found for checked components")
PYEOF
```

**Severity:**
- ðŸ”´ Critical if CVE with CVSS â‰¥ 9.0 found in a deployed component
- ðŸŸ¡ Warning if CVE with CVSS â‰¥ 7.0 found (high severity)
- ðŸŸ¢ OK if no CVEs found or only low/informational

---

## 5. Authentik Security Log Analysis

**Objective**: Detect failed logins, brute force, and unusual access in Authentik logs.

**Commands:**

```bash
# Port-forward to Elasticsearch
kubectl port-forward -n monitoring svc/elasticsearch-es-http 9200:9200 &
ES_PID=$!
sleep 3

ES_PASS=$(kubectl get secret elasticsearch-es-elastic-user -n monitoring \
  -o jsonpath='{.data.elastic}' | base64 -d)

echo "=== Authentik failed login attempts (last 7 days) ==="
curl -sk -u "elastic:${ES_PASS}" \
  "https://localhost:9200/fluent-bit-*/_search" \
  -H 'Content-Type: application/json' -d '{
    "size": 50,
    "query": {
      "bool": {
        "must": [
          {"match": {"kubernetes.namespace_name": "kube-system"}},
          {"bool": {"should": [
            {"match_phrase": {"log": "Login failed"}},
            {"match_phrase": {"log": "Failed to authenticate"}},
            {"match_phrase": {"log": "invalid_grant"}},
            {"match_phrase": {"log": "FAILED_LOGIN"}}
          ]}}
        ],
        "filter": {"range": {"@timestamp": {"gte": "now-7d"}}}
      }
    },
    "aggs": {
      "by_ip": {"terms": {"field": "clientAddress.keyword", "size": 20}}
    }
  }' | python3 -c "
import sys, json, os
d = json.load(sys.stdin)
domain = os.environ.get('DOMAIN', '[DOMAIN]')
total = d['hits']['total']['value']
print(f'Total failed login events (7d): {total}')
buckets = d.get('aggregations', {}).get('by_ip', {}).get('buckets', [])
if buckets:
    print('Top source IPs:')
    for b in buckets:
        print(f'  {b[\"key\"]}: {b[\"doc_count\"]} failures')
for h in d['hits']['hits'][:10]:
    log = h['_source'].get('log', '')[:120].replace(domain, '[DOMAIN]')
    print(f'  {log}')
" 2>/dev/null

kill $ES_PID 2>/dev/null
```

**Expected results:**
- Zero or low failed login count
- No single IP with >20 failures in 1 hour

**Severity:**
- ðŸ”´ Critical if >20 failed logins from single IP within 1 hour (brute force indicator)
- ðŸŸ¡ Warning if failed logins from unexpected geographies or unusual user agents

---

## 6. External Service Attack Pattern Analysis

**Objective**: Detect scanning, injection attempts, and unusual traffic against externally exposed services.

Expected external services: `authentik`, `langfuse`, `nextcloud`, `paperless-ngx`, `uptime-kuma`, `music-assistant`

**Commands:**

```bash
kubectl port-forward -n monitoring svc/elasticsearch-es-http 9200:9200 &
ES_PID=$!
sleep 3

ES_PASS=$(kubectl get secret elasticsearch-es-elastic-user -n monitoring \
  -o jsonpath='{.data.elastic}' | base64 -d)

echo "=== Attack pattern hits in ingress logs (last 24h) ==="
curl -sk -u "elastic:${ES_PASS}" \
  "https://localhost:9200/fluent-bit-*/_search" \
  -H 'Content-Type: application/json' -d '{
    "size": 100,
    "query": {
      "bool": {
        "must": [
          {"match": {"kubernetes.namespace_name": "network"}},
          {"bool": {"should": [
            {"match_phrase": {"log": "../"}},
            {"match_phrase": {"log": "etc/passwd"}},
            {"match_phrase": {"log": "SELECT "}},
            {"match_phrase": {"log": "<script"}},
            {"match_phrase": {"log": "wp-login"}},
            {"match_phrase": {"log": ".env"}},
            {"match_phrase": {"log": "phpMyAdmin"}},
            {"match_phrase": {"log": "cmd.exe"}},
            {"match_phrase": {"log": "/bin/sh"}}
          ]}}
        ],
        "filter": {"range": {"@timestamp": {"gte": "now-24h"}}}
      }
    },
    "aggs": {
      "by_ip": {"terms": {"field": "remote_addr.keyword", "size": 10}}
    }
  }' | python3 -c "
import sys, json, os
d = json.load(sys.stdin)
domain = os.environ.get('DOMAIN', '[DOMAIN]')
total = d['hits']['total']['value']
print(f'Attack pattern hits (24h): {total}')
buckets = d.get('aggregations', {}).get('by_ip', {}).get('buckets', [])
if buckets:
    print('Top attacker IPs:')
    for b in buckets:
        print(f'  {b[\"key\"]}: {b[\"doc_count\"]} hits')
for h in d['hits']['hits'][:10]:
    log = h['_source'].get('log', '')[:120].replace(domain, '[DOMAIN]')
    print(f'  {log}')
" 2>/dev/null

echo ""
echo "=== 5xx error rate by service (last 24h) ==="
curl -sk -u "elastic:${ES_PASS}" \
  "https://localhost:9200/fluent-bit-*/_search" \
  -H 'Content-Type: application/json' -d '{
    "size": 0,
    "query": {
      "bool": {
        "must": [{"match": {"kubernetes.namespace_name": "network"}}],
        "filter": [
          {"range": {"@timestamp": {"gte": "now-24h"}}},
          {"regexp": {"log": "\" [5][0-9]{2} "}}
        ]
      }
    },
    "aggs": {"by_service": {"terms": {"field": "kubernetes.container_name.keyword", "size": 10}}}
  }' | python3 -c "
import sys, json
d = json.load(sys.stdin)
buckets = d.get('aggregations', {}).get('by_service', {}).get('buckets', [])
total_5xx = sum(b['doc_count'] for b in buckets)
print(f'Total 5xx errors (24h): {total_5xx}')
for b in buckets:
    print(f'  {b[\"key\"]}: {b[\"doc_count\"]}')
" 2>/dev/null

kill $ES_PID 2>/dev/null
```

**Severity:**
- ðŸ”´ Critical if HTTP 200 response to path traversal / injection pattern (successful exploitation)
- ðŸŸ¡ Warning if >100 attack pattern requests per hour from single IP (active scanner)
- ðŸŸ¡ Warning if 5xx rate >1% of total requests for a service

---

## 7. RBAC & Pod Security Audit

**Objective**: Identify overly permissive roles and insecure pod configurations.

**Commands:**

```bash
echo "=== ClusterRoles with wildcard verbs or resources (non-system) ==="
kubectl get clusterroles -o json | python3 -c "
import sys, json
roles = json.load(sys.stdin)['items']
found = False
for r in roles:
    name = r['metadata']['name']
    if name.startswith('system:'): continue
    for rule in r.get('rules', []):
        if '*' in rule.get('verbs', []) or '*' in rule.get('resources', []):
            print(f'ðŸŸ¡ {name}: {rule}')
            found = True
if not found:
    print('ðŸŸ¢ No non-system ClusterRoles with wildcard permissions')
"

echo ""
echo "=== Privileged containers ==="
kubectl get pods -A -o json | python3 -c "
import sys, json
pods = json.load(sys.stdin)['items']
found = False
for p in pods:
    ns = p['metadata']['namespace']
    name = p['metadata']['name']
    psc = p['spec'].get('securityContext', {})
    for c in p['spec'].get('containers', []) + p['spec'].get('initContainers', []):
        sc = c.get('securityContext', {})
        cname = c['name']
        if sc.get('privileged'):
            print(f'ðŸ”´ PRIVILEGED: {ns}/{name} container={cname}')
            found = True
        uid = sc.get('runAsUser', psc.get('runAsUser'))
        if uid == 0:
            print(f'ðŸŸ¡ ROOT (uid=0): {ns}/{name} container={cname}')
            found = True
if not found:
    print('ðŸŸ¢ No privileged containers or explicit root uid=0 found')
"

echo ""
echo "=== hostNetwork / hostPID pods ==="
kubectl get pods -A -o json | python3 -c "
import sys, json
pods = json.load(sys.stdin)['items']
found = False
for p in pods:
    spec = p['spec']
    ns, name = p['metadata']['namespace'], p['metadata']['name']
    if spec.get('hostNetwork'):
        print(f'ðŸŸ¡ hostNetwork: {ns}/{name}')
        found = True
    if spec.get('hostPID'):
        print(f'ðŸŸ¡ hostPID: {ns}/{name}')
        found = True
if not found:
    print('ðŸŸ¢ No pods with hostNetwork or hostPID')
"

echo ""
echo "=== Pods with hostPath volumes ==="
kubectl get pods -A -o json | python3 -c "
import sys, json
pods = json.load(sys.stdin)['items']
found = False
for p in pods:
    ns, name = p['metadata']['namespace'], p['metadata']['name']
    for v in p['spec'].get('volumes', []):
        if 'hostPath' in v:
            path = v['hostPath'].get('path', '?')
            print(f'ðŸŸ¡ hostPath({path}): {ns}/{name}')
            found = True
if not found:
    print('ðŸŸ¢ No pods with hostPath volumes')
"
```

**Severity:**
- ðŸ”´ Critical if privileged container found outside known system namespaces (`kube-system`, `monitoring`, `storage`)
- ðŸŸ¡ Warning for wildcard RBAC, hostNetwork/hostPID, or hostPath mounts in application namespaces

---

## 8. External Exposure Inventory

**Objective**: Confirm only expected services are publicly reachable; flag surprises.

Expected external ingresses: `authentik`, `langfuse`, `flux-webhook`, `music-assistant` (alexa endpoints), `uptime-kuma`, `nextcloud`, `paperless-ngx`

**Commands:**

```bash
echo "=== All external-class ingresses ==="
kubectl get ingress -A -o json | python3 -c "
import sys, json, os
items = json.load(sys.stdin)['items']
domain = os.environ.get('DOMAIN', '[DOMAIN]')
for i in items:
    if i['spec'].get('ingressClassName') == 'external':
        ns = i['metadata']['namespace']
        name = i['metadata']['name']
        hosts = [r.get('host','').replace(domain, '[DOMAIN]')
                 for r in i['spec'].get('rules', [])]
        print(f'  {ns}/{name}: {hosts}')
" | sort

echo ""
echo "=== LoadBalancer services with external IPs ==="
kubectl get svc -A --field-selector spec.type=LoadBalancer \
  -o custom-columns='NAMESPACE:.metadata.namespace,NAME:.metadata.name,EXTERNAL-IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[*].port'

echo ""
echo "=== NodePort services (may be externally reachable) ==="
kubectl get svc -A --field-selector spec.type=NodePort \
  -o custom-columns='NAMESPACE:.metadata.namespace,NAME:.metadata.name,PORT:.spec.ports[*].nodePort'
```

**Expected results:** Only the listed expected services appear with `ingressClassName: external`.

**Severity:**
- ðŸ”´ Critical if unexpected service found in external ingress class
- ðŸŸ¡ Warning for unexpected NodePort or LoadBalancer service with public IP

---

## 9. Certificate Integrity

**Objective**: Verify all TLS certificates are valid and not expiring within 14 days.

**Commands:**

```bash
echo "=== cert-manager certificate status ==="
kubectl get certificate -A \
  -o custom-columns='NS:.metadata.namespace,NAME:.metadata.name,READY:.status.conditions[0].status,EXPIRY:.status.notAfter'

echo ""
echo "=== TLS validity check for external hostnames ==="
for host in auth nextcloud paperless langfuse; do
  result=$(echo | openssl s_client \
    -connect "${host}.${DOMAIN}:443" \
    -servername "${host}.${DOMAIN}" \
    2>/dev/null | openssl x509 -noout -dates -issuer 2>/dev/null)

  if [ -z "$result" ]; then
    echo "  ðŸŸ¡ ${host}.[DOMAIN]: could not connect or no cert"
    continue
  fi

  expiry=$(echo "$result" | grep 'notAfter' | cut -d= -f2)
  issuer=$(echo "$result" | grep 'issuer' | sed 's/.*O = //' | cut -d, -f1)

  # Calculate days remaining
  expiry_epoch=$(date -d "$expiry" +%s 2>/dev/null || date -j -f "%b %d %T %Y %Z" "$expiry" +%s 2>/dev/null)
  now_epoch=$(date +%s)
  days_left=$(( (expiry_epoch - now_epoch) / 86400 ))

  if [ "$days_left" -lt 0 ]; then
    echo "  ðŸ”´ ${host}.[DOMAIN]: EXPIRED ($expiry)"
  elif [ "$days_left" -lt 14 ]; then
    echo "  ðŸ”´ ${host}.[DOMAIN]: expires in ${days_left}d ($expiry) â€” URGENT"
  else
    echo "  ðŸŸ¢ ${host}.[DOMAIN]: valid ${days_left}d, issuer=$issuer"
  fi
done
```

**Severity:**
- ðŸ”´ Critical if cert is expired or expires within 14 days (cert-manager renewal likely broken)
- ðŸŸ¡ Warning if issuer is not Let's Encrypt (unexpected CA)

---

## 10. Flux Security Posture

**Objective**: Verify Flux webhook has auth token, SOPS age key is present, and Git credentials are encrypted.

**Commands:**

```bash
echo "=== SOPS age key in flux-system ==="
kubectl get secret sops-age -n flux-system \
  -o jsonpath='{.metadata.name}' 2>/dev/null \
  && echo " ðŸŸ¢ sops-age secret present" \
  || echo "ðŸ”´ sops-age secret NOT FOUND â€” Flux cannot decrypt secrets"

echo ""
echo "=== Flux webhook receiver secret refs ==="
kubectl get receiver -n flux-system -o json 2>/dev/null | python3 -c "
import sys, json
items = json.load(sys.stdin).get('items', [])
if not items:
    print('  (no receivers configured)')
for r in items:
    name = r['metadata']['name']
    secret_ref = r['spec'].get('secretRef', {}).get('name', 'NONE')
    if secret_ref == 'NONE':
        print(f'ðŸ”´ {name}: NO secretRef â€” webhook is unauthenticated')
    else:
        print(f'ðŸŸ¢ {name}: secretRef={secret_ref}')
" 2>/dev/null

echo ""
echo "=== Git repository credential check ==="
kubectl get gitrepository -A -o json | python3 -c "
import sys, json
for r in json.load(sys.stdin)['items']:
    ns, name = r['metadata']['namespace'], r['metadata']['name']
    url = r['spec'].get('url', '')
    # Credentials in URL = bad (e.g. https://user:token@github.com/...)
    if '@' in url and '://' in url:
        print(f'ðŸ”´ Credentials in URL: {ns}/{name} url={url}')
    else:
        ref = r['spec'].get('secretRef', {})
        secret = ref.get('name', '(none)') if ref else '(none)'
        print(f'ðŸŸ¢ {ns}/{name}: url uses secretRef={secret}')
"

echo ""
echo "=== Flux subjects with cluster-admin binding ==="
kubectl get clusterrolebindings -o json | python3 -c "
import sys, json
found = False
for b in json.load(sys.stdin)['items']:
    if b['roleRef']['name'] == 'cluster-admin':
        subjects = [s.get('name','?') for s in b.get('subjects',[])]
        if any('flux' in s.lower() for s in subjects):
            print(f'ðŸŸ¡ Flux subject has cluster-admin: binding={b[\"metadata\"][\"name\"]} subjects={subjects}')
            found = True
if not found:
    print('ðŸŸ¢ No Flux subjects bound to cluster-admin')
"

echo ""
echo "=== SOPS path_regex coverage ==="
python3 -c "
import re
with open('.sops.yaml') as f:
    content = f.read()
# Extract path_regex patterns
patterns = re.findall(r'path_regex:\s*(.+)', content)
print('Configured path_regex rules:')
for p in patterns:
    print(f'  {p.strip()}')
"
```

**Severity:**
- ðŸ”´ Critical if `sops-age` secret missing (cluster cannot decrypt secrets on startup)
- ðŸ”´ Critical if webhook receiver has no secretRef (unauthenticated webhook = supply chain risk)
- ðŸŸ¡ Warning if any Flux service account has `cluster-admin` binding

---

## 11. UniFi Network Security Audit

**Objective**: Check UniFi controller for IDS/IPS alerts, firewall anomalies, unknown devices, and admin login events.

**Note**: `unifictl` must be configured per CLAUDE.md prerequisites before running.

**Commands:**

```bash
echo "=== IDS/IPS threat events ==="
unifictl local events -o json 2>/dev/null | python3 -c "
import sys, json
try:
    events = json.load(sys.stdin)
except Exception:
    print('Could not parse events JSON')
    exit(0)
threats = [e for e in events if any(
    k in str(e).upper() for k in ['IDS','IPS','THREAT','INTRUSION','MALWARE','EXPLOIT']
)]
print(f'IDS/IPS events: {len(threats)}')
if threats:
    for e in threats[:10]:
        print(f'  {json.dumps(e)[:120]}')
else:
    print('ðŸŸ¢ No IDS/IPS events found')
"

echo ""
echo "=== Firewall / security event keys ==="
unifictl local events -o json 2>/dev/null | python3 -c "
import sys, json
try:
    events = json.load(sys.stdin)
except Exception:
    print('Could not parse events JSON')
    exit(0)
security_events = []
for e in events:
    key = e.get('key', '')
    if any(key.startswith(p) for p in ['EVT_IDS','EVT_FW','EVT_LU','EVT_WG']):
        msg = e.get('msg', e.get('message', str(e)))[:100]
        security_events.append(f'[{key}] {msg}')
print(f'Security-category events: {len(security_events)}')
for ev in security_events[:20]:
    print(f'  {ev}')
if not security_events:
    print('ðŸŸ¢ No firewall/login security events')
"

echo ""
echo "=== Unadopted / unknown devices (potential rogue hardware) ==="
unifictl local devices --unadopted 2>/dev/null

echo ""
echo "=== New wireless clients in last 24h ==="
unifictl local clients -o json 2>/dev/null | python3 -c "
import sys, json, time
try:
    clients = json.load(sys.stdin)
except Exception:
    print('Could not parse clients JSON')
    exit(0)
threshold = time.time() - 86400
new = [c for c in clients if c.get('first_seen', 0) > threshold]
print(f'New clients in last 24h: {len(new)}')
for c in new:
    mac  = c.get('mac', '?')
    name = c.get('name', c.get('hostname', '?'))
    net  = c.get('network', '?')
    print(f'  MAC:{mac} Name:{name} Network:{net}')
if not new:
    print('ðŸŸ¢ No new clients in last 24h')
"

echo ""
echo "=== Blocked clients (confirm list is intentional) ==="
unifictl local clients --blocked -o json 2>/dev/null | python3 -c "
import sys, json
try:
    blocked = json.load(sys.stdin)
except Exception:
    print('Could not parse blocked clients JSON')
    exit(0)
print(f'Blocked clients: {len(blocked)}')
for c in blocked:
    print(f'  {c.get(\"mac\",\"?\")} {c.get(\"name\", c.get(\"hostname\",\"?\"))}')
if not blocked:
    print('(no blocked clients)')
"

echo ""
echo "=== WAN status ==="
unifictl local wan 2>/dev/null | head -20

echo ""
echo "=== Admin login events ==="
unifictl local events -o json 2>/dev/null | python3 -c "
import sys, json
try:
    events = json.load(sys.stdin)
except Exception:
    print('Could not parse events JSON')
    exit(0)
admin_events = [e for e in events
                if 'EVT_LU' in e.get('key','') or 'admin' in str(e).lower()]
print(f'Admin/login events: {len(admin_events)}')
for e in admin_events[:5]:
    print(f'  {json.dumps(e)[:120]}')
if not admin_events:
    print('ðŸŸ¢ No admin login events in recent history')
"
```

**Severity:**
- ðŸ”´ Critical if IDS/IPS `threat` classification event detected
- ðŸ”´ Critical if unadopted device found on Trusted (VLAN 1) or Servers (VLAN 10) network
- ðŸŸ¡ Warning if new device on IoT VLAN not recognised
- ðŸŸ¡ Warning if repeated firewall denies from same external IP (active scanner)
- ðŸŸ¡ Warning if admin login from unexpected IP or time

---

## Report Generation

After completing all 11 sections, append the summary table to `runbooks/security-check-current.md`:

```bash
cat >> runbooks/security-check-current.md << 'SUMMARY_EOF'

---

## Summary Table

| Section | Status | Findings |
|---------|--------|----------|
| 1. SOPS Encryption Coverage | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 2. Sensitive Data Exposure | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 3. Git History Secret Scan | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 4. CVE / Vulnerability Check | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 5. Authentik Login Analysis | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 6. External Attack Patterns | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 7. RBAC & Pod Security | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 8. External Exposure Inventory | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 9. Certificate Integrity | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 10. Flux Security Posture | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |
| 11. UniFi Network Security | ðŸŸ¢/ðŸŸ¡/ðŸ”´ | |

_Replace ðŸŸ¢/ðŸŸ¡/ðŸ”´ placeholders with actual status and fill in finding counts._
SUMMARY_EOF
```

---

## Output File Redaction Reminder

Before saving `runbooks/security-check-current.md`, verify no sensitive values leaked through:

```bash
# These should all return 0
grep -c "$DOMAIN"    runbooks/security-check-current.md && echo "âš ï¸  DOMAIN found" || echo "âœ… domain clean"
grep -c "$GIT_NAME"  runbooks/security-check-current.md && echo "âš ï¸  NAME found"   || echo "âœ… name clean"
grep -c "$GIT_EMAIL" runbooks/security-check-current.md && echo "âš ï¸  EMAIL found"  || echo "âœ… email clean"
```

---

## Execution Schedule

| Trigger | Frequency |
|---------|-----------|
| Routine security review | Monthly |
| After new external service deployed | On deploy |
| After Renovate security-labeled PR merged | On merge |
| After UniFi firmware or config change | On change |
| When cluster alert fires (Authentik errors, cert expiry) | On alert |
